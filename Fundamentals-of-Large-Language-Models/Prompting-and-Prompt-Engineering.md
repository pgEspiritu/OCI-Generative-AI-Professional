# ğŸ§  Lesson 3: Prompting in Large Language Models

---

## ğŸ’¬ What Is Prompting?

Letâ€™s revisit our familiar sentence:

> â€œI wrote to the zoo to send me a pet. They sent me a ___.â€

As we know, an LLM computes a **distribution** over possible next words.  
Prompting refers to **how we can influence this distribution** â€” that is, how to make certain words more or less likely.  

There are **two main ways** to affect this distribution:
1. ğŸª„ **Prompting** â€“ by changing the input text itself  
2. ğŸ§  **Training** â€“ by adjusting the modelâ€™s parameters (weâ€™ll cover this later)

---

## ğŸª„ Prompting: Changing the Input Text

Prompting is simply about **altering the content or structure of the input** passed to the model.  

Even small changes â€” like adding or removing a single word â€” can **significantly shift the probabilities** of the modelâ€™s vocabulary.

### ğŸ¾ Example
If we modify our earlier prompt to:

> â€œI wrote to the zoo to send me a **little** pet. They sent me a ___.â€

...the model might increase probabilities for **small animals** (ğŸ­ â€œmouse,â€ ğŸ¹ â€œhamsterâ€)  
and decrease probabilities for **large animals** (ğŸ¦ â€œlion,â€ ğŸ˜ â€œelephantâ€).  

Thatâ€™s because during **pre-training**, the model learns statistical patterns â€” e.g., *â€œlittle catâ€* appears far more often than *â€œlittle lion.â€*  

---

## ğŸ§± How the Model Learns This

During **pre-training**, the LLM is shown **massive amounts of text** and learns to predict the next word in a sequence.  
Through this process, it learns:
- Common phrases and patterns (e.g., â€œlittle dog,â€ â€œbig elephantâ€)  
- The likelihood of certain word combinations  
- General world knowledge ğŸ§   

So when we prompt the model differently, weâ€™re indirectly tapping into these learned relationships.

---

## ğŸ§  What Is Prompt Engineering?

**Prompt engineering** is the process of **refining your input text** to guide the model toward a desired output.  

Itâ€™s often done **iteratively** â€” by experimenting with phrasing, context, or examples until the results look right.

However:
- âš ï¸ It can be **unpredictable** â€” even small tweaks (like whitespace!) can drastically change output.
- ğŸŒ€ You might rephrase an input (e.g., â€œI wanted a pet, so I asked the zoo to send me oneâ€¦â€) and get a completely different response.

Despite the unpredictability, **prompt engineering can be extremely powerful** â€” especially for well-defined tasks.  
Many organizations and researchers use it to tune model behavior effectively.

---

## ğŸ§© In-Context Learning (a.k.a. Example-Based Prompting)

One of the most effective prompt engineering strategies is called **In-Context Learning**.  
Despite the name, this technique does **not** involve the model *learning* new parameters.

Instead, we construct a prompt that **shows examples** (called *demonstrations*) of the task before asking the model to complete a similar one.

### ğŸ“˜ Example: *3-Shot Prompting* (from the GPT-3 paper)
Translate English to French:
```text
sea -> mer
book -> livre
computer -> ordinateur
chair ->
```

Here:
- The model sees **3 examples** (â†’ â€œ3-shot promptingâ€)
- It learns from the **pattern** in the input
- It completes the final translation: `chair -> chaise`

---

### ğŸ§® Terminology Note

The term *prompt* is often **overloaded**:
- Sometimes it refers to the **entire input text** sent to the model.
- Other times it refers only to the **final query portion** (after examples).  

Itâ€™s important to be aware of how others use the term in different contexts.

---

## ğŸ”¢ K-Shot vs. Zero-Shot Prompting

| Type | Description | Example |
|-------|--------------|----------|
| ğŸ§  **Zero-Shot** | No examples, just instructions | â€œTranslate â€˜appleâ€™ to French.â€ |
| ğŸ’¡ **One-Shot** | One example + task | â€œcat -> chat, apple -> â€ |
| ğŸ§© **K-Shot** | Several examples (k = number of demonstrations) | 3-shot example above |

Studies show that **including demonstrations** (1-shot or k-shot) often yields **better performance** than zero-shot prompting.

---

## ğŸ§® Examples of Different Prompt Styles

Letâ€™s explore a few **real prompt examples** that highlight the variety of prompt engineering styles:

### 1ï¸âƒ£ **Two-Shot Arithmetic Prompt**
```text
2 + 3: 5
4 + 5: 9
1 + 8:
```

ğŸ§  The model doesnâ€™t actually â€œcomputeâ€ the sum â€” it learns from examples that numbers after `:` are expected answers.

---

### 2ï¸âƒ£ **Instruction Prompt (from MPT-Instruct)**

Follow these instructions carefully. Be concise.

Instruction:

Write a SQL query to count the number of users registered in 2024.

Response:
This structure tells the model exactly what format and style to use.

---

### 3ï¸âƒ£ **Long, Detailed System Prompt**
These were famously used in early Bing Chat and research examples.  
They often include detailed instructions like:
> â€œIf you donâ€™t know the answer, reply: â€˜Iâ€™m not sure.â€™ Do not guess. Stay polite. Format output as markdown.â€

Such prompts define the modelâ€™s **tone, constraints, and behavior**. ğŸ­

---

## ğŸ”— Advanced Prompting Strategies

### ğŸ§µ Chain-of-Thought Prompting (CoT)

Introduced in 2022, **Chain-of-Thought prompting** encourages the model to **show its reasoning steps** for complex problems.

#### ğŸ§© Example:
> Q: If there are 3 red balls and 2 blue balls in a bag, and I add 4 more red balls, how many are red in total?  
>
> A: There are 3 red balls initially. I add 4 more, so 3 + 4 = **7 red balls**.

Instead of jumping to the answer, the model **writes intermediate reasoning steps**, leading to **more accurate multi-step reasoning**.

ğŸ§  Why it works:
- The model might have seen **step-by-step reasoning examples** during pre-training.  
- Or, breaking a problem into smaller chunks makes it **easier for the model to handle**.

---

### ğŸªœ Least-to-Most Prompting

Another variant that builds on CoT â€” introduced in later research.

Here, the model solves **simpler subproblems first**, then uses those results to tackle **harder problems**.

ğŸ§® Example:
Given words `["think", "machine", "learning"]`, concatenate the **last letters**.

- Step 1: â€œthinkâ€ â†’ **k**
- Step 2: â€œmachineâ€ â†’ **e**
- Step 3: Combine â†’ **ke**
- Step 4: â€œlearningâ€ â†’ **g**
- Final: â€œkeâ€ + â€œgâ€ â†’ **keg**

This incremental reasoning tends to improve accuracy compared to direct prompting.

---

### âš›ï¸ Concept-Based Prompting (DeepMind)

Researchers at **DeepMind** found that prompting models to **explicitly recall relevant concepts or formulas** improves their accuracy in subjects like physics and chemistry.

Example:
> â€œTo solve this, recall Newtonâ€™s Second Law: F = ma.â€

By prompting the model to state the *principles* first, it anchors its reasoning and produces better solutions. ğŸ”¬

---

## ğŸ§¾ Summary

| Concept | Description |
|----------|--------------|
| ğŸª„ **Prompting** | Influencing LLM output by modifying input text |
| ğŸ§  **Prompt Engineering** | Crafting inputs iteratively to improve outputs |
| ğŸ§© **In-Context Learning** | Showing examples within the prompt |
| ğŸ§µ **Chain-of-Thought** | Guiding models to â€œshow their reasoningâ€ |
| ğŸªœ **Least-to-Most** | Solving simpler problems first |
| âš›ï¸ **Concept-Based** | Including principles or equations for scientific reasoning |

---

## âœ… Key Takeaways

- Prompting lets us control LLM behavior **without retraining**.  
- Small input changes can yield **big output differences**.  
- Prompt engineering is **both art and science** â€” sometimes unpredictable, but highly effective.  
- Advanced strategies like **Chain-of-Thought** and **Least-to-Most** prompting can unlock deeper reasoning abilities.  
